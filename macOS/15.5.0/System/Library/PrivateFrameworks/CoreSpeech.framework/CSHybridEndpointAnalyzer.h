@class NSDate, OSDFeatures, NSString, CSAudioRecordContext, CSASRFeatures, _EAREndpointer, NSObject, CSAsset, NSMutableArray, OSDAnalyzer;
@protocol OS_dispatch_queue, CSEndpointAnalyzerDelegate, CSEndpointAnalyzerImplDelegate;

@interface CSHybridEndpointAnalyzer : NSObject <CSAssetManagerDelegate, OSDAnalyzerDelegate, CSEndpointAnalyzerImpl>

@property (retain, nonatomic) CSAsset *currentAsset;
@property (retain, nonatomic) NSObject<OS_dispatch_queue> *apQueue;
@property (nonatomic) unsigned long long numSamplesProcessed;
@property (nonatomic) unsigned long long numSamplesProcessedBeforeAnchorTime;
@property (nonatomic) unsigned long long anchorMachAbsTime;
@property (nonatomic) BOOL isAnchorTimeBuffered;
@property (nonatomic) BOOL isRequestTimeout;
@property (nonatomic) BOOL didAddAudio;
@property (retain, nonatomic) OSDAnalyzer *osdAnalyzer;
@property (retain, nonatomic) OSDFeatures *osdFeaturesAtEndpoint;
@property (nonatomic) BOOL canProcessCurrentRequest;
@property (retain, nonatomic) _EAREndpointer *hybridClassifier;
@property (retain, nonatomic) NSString *endpointerModelVersion;
@property (retain, nonatomic) NSObject<OS_dispatch_queue> *asrFeaturesQueue;
@property (retain, nonatomic) CSASRFeatures *lastKnownASRFeatures;
@property (retain, nonatomic) OSDFeatures *lastKnownOSDFeatures;
@property (retain, nonatomic) NSMutableArray *asrFeatureLatencies;
@property (nonatomic) double lastKnownASRFeatureLatency;
@property (nonatomic) BOOL epResult;
@property (nonatomic) double asrFeaturesWarmupLatency;
@property (retain, nonatomic) NSDate *lastASRFeatureTimestamp;
@property (nonatomic) BOOL didReceiveASRFeatures;
@property (nonatomic) double clientLagThresholdMs;
@property (nonatomic) double clampedASRFeatureLatencyMsForClientLag;
@property (nonatomic) BOOL useDefaultASRFeaturesOnClientLag;
@property (retain, nonatomic) NSObject<OS_dispatch_queue> *hybridClassifierQueue;
@property (nonatomic) double lastReportedEndpointTimeMs;
@property (nonatomic) double processedAudioInSeconds;
@property (nonatomic) float lastEndpointPosterior;
@property (retain, nonatomic) NSObject<OS_dispatch_queue> *stateSerialQueue;
@property (nonatomic) BOOL didCommunicateEndpoint;
@property (nonatomic) unsigned long long currentRequestSampleRate;
@property (nonatomic) double vtExtraAudioAtStartInMs;
@property (nonatomic) unsigned long long vtEndInSampleCount;
@property (nonatomic) double hepAudioOriginInMs;
@property (nonatomic) double twoShotSilenceThresholdInMs;
@property (nonatomic) BOOL didNotifyTwoShot;
@property (retain, nonatomic) CSAudioRecordContext *recordContext;
@property (nonatomic) BOOL speechEndpointDetected;
@property (retain, nonatomic) NSDate *firstAudioPacketTimestamp;
@property (nonatomic) double firstAudioSampleSensorTimestamp;
@property (nonatomic) BOOL didTimestampFirstAudioPacket;
@property (nonatomic) BOOL recordingDidStop;
@property (retain, nonatomic) NSObject<OS_dispatch_queue> *osdQueue;
@property (nonatomic) BOOL didDetectSpeech;
@property (nonatomic) double postVoiceTriggerSilence;
@property (readonly) unsigned long long hash;
@property (readonly) Class superclass;
@property (readonly, copy) NSString *description;
@property (readonly, copy) NSString *debugDescription;
@property (weak, nonatomic) id<CSEndpointAnalyzerDelegate> delegate;
@property (weak, nonatomic) id<CSEndpointAnalyzerImplDelegate> implDelegate;
@property (nonatomic) unsigned long long activeChannel;
@property (nonatomic) long long endpointStyle;
@property (nonatomic) double delay;
@property (nonatomic) double startWaitTime;
@property (nonatomic) double automaticEndpointingSuspensionEndTime;
@property (nonatomic) double minimumDurationForEndpointer;
@property (readonly, nonatomic) double lastEndOfVoiceActivityTime;
@property (readonly, nonatomic) double lastStartOfVoiceActivityTime;
@property (nonatomic) double bypassSamples;
@property (nonatomic) double interspeechWaitTime;
@property (nonatomic) double endWaitTime;
@property (nonatomic) BOOL saveSamplesSeenInReset;
@property (retain, nonatomic) NSString *mhId;

- (id)init;
- (void).cxx_destruct;
- (void)reset;
- (void)CSAssetManagerDidDownloadNewAsset:(id)a0;
- (void)CSLanguageCodeUpdateMonitor:(id)a0 didReceiveLanguageCodeChanged:(id)a1;
- (void)_updateAssetWithCurrentLanguage;
- (void)preheat;
- (void)updateEndpointerDelayedTrigger:(BOOL)a0;
- (void)_emitEndpointDetectedEventWithEndpointTimeMs:(double)a0 endpointBufferHostTime:(unsigned long long)a1 endpointerFeatures:(id)a2 endpointerDecisionLagInNs:(double)a3 extraDelayMs:(unsigned long long)a4 endpointScore:(double)a5 asrFeaturesLatencies:(id)a6;
- (id)_getCSHybridEndpointerConfigForAsset:(id)a0;
- (id)_getSerialQueueWithName:(id)a0 targetQueue:(id)a1;
- (void)_loadAndSetupEndpointerAssetIfNecessary;
- (BOOL)_multimodalEndpointerEnabled;
- (void)_readParametersFromHEPAsset:(id)a0;
- (BOOL)_shouldProvideTwoShotFeedbackWithRecordContext;
- (void)_updateAssetWithLanguage:(id)a0;
- (long long)fetchCurrentEndpointerOperationMode;
- (void)handleVoiceTriggerWithActivationInfo:(id)a0;
- (void)logFeaturesWithEvent:(id)a0 locale:(id)a1;
- (void)osdAnalyzer:(id)a0 didUpdateOSDFeatures:(id)a1;
- (void)processASRFeatures:(id)a0 fromServer:(BOOL)a1;
- (void)processAudioSamplesAsynchronously:(id)a0;
- (void)recordingStoppedForReason:(long long)a0;
- (void)resetForNewRequestWithSampleRate:(unsigned long long)a0 recordContext:(id)a1 disableRCSelection:(BOOL)a2;
- (void)setEndpointerOperationMode:(long long)a0;
- (void)shouldAcceptEagerResultForDuration:(double)a0 resultsCompletionHandler:(id /* block */)a1;
- (void)stopEndpointer;
- (void)terminateProcessing;
- (void)updateEndpointerThreshold:(float)a0;

@end
