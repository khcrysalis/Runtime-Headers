@class NSString, NSArray, NSURL, NSDictionary, MPSGraph, NSObject, MPSGraphCompilationDescriptor, NSFileManager;
@protocol OS_dispatch_queue;

@interface MPSGraphExecutable : MPSGraphObject {
    MPSGraph *_graph;
    struct shared_ptr<mlir::MLIRContext> { struct MLIRContext *__ptr_; struct __shared_weak_count *__cntrl_; } _executableContext;
    void *_builder;
    struct LazyLoadableModuleRef { struct shared_ptr<mlir::MLIRContext> { struct MLIRContext *__ptr_; struct __shared_weak_count *__cntrl_; } _ctx; struct OwningOpRef<mlir::ModuleOp> { struct ModuleOp { struct Operation *state; } op; } _originalModule; NSURL *_moduleURL; struct shared_ptr<ModuleResourcesLoader> { struct ModuleResourcesLoader *__ptr_; struct __shared_weak_count *__cntrl_; } _resourceLoader; } _originalModule;
    void *_symbolTable;
    MPSGraphCompilationDescriptor *_originalCompilationDescriptor;
    NSDictionary *_callablesDescription;
    struct DenseMap<const void *, std::unique_ptr<RuntimeCacheEntry>, llvm::DenseMapInfo<const void *>, llvm::detail::DenseMapPair<const void *, std::unique_ptr<RuntimeCacheEntry>>> { void *Buckets; unsigned int NumEntries; unsigned int NumTombstones; unsigned int NumBuckets; } _newRuntimeCache;
    struct DenseMap<MPSGraphModuleKey, std::unique_ptr<LazyLoadableModuleRef>, MPSGraphModuleKeyInfo, llvm::detail::DenseMapPair<MPSGraphModuleKey, std::unique_ptr<LazyLoadableModuleRef>>> { void *Buckets; unsigned int NumEntries; unsigned int NumTombstones; unsigned int NumBuckets; } _optimizedModuleCache;
    struct unordered_map<std::string, LazyLoadableModuleRef, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<const std::string, LazyLoadableModuleRef>>> { struct __hash_table<std::__hash_value_type<std::string, LazyLoadableModuleRef>, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, LazyLoadableModuleRef>, std::hash<std::string>, std::equal_to<std::string>>, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, LazyLoadableModuleRef>, std::equal_to<std::string>, std::hash<std::string>>, std::allocator<std::__hash_value_type<std::string, LazyLoadableModuleRef>>> { struct unique_ptr<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> *[], std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> *>>> { struct __compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> **, std::__bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> *>>> { void **__value_; struct __bucket_list_deallocator<std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> *>> { struct __compressed_pair<unsigned long, std::allocator<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> *>> { unsigned long long __value_; } __data_; } __value_; } __ptr_; } __bucket_list_; struct __compressed_pair<std::__hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *>, std::allocator<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *>>> { struct __hash_node_base<std::__hash_node<std::__hash_value_type<std::string, LazyLoadableModuleRef>, void *> *> { void *__next_; } __value_; } __p1_; struct __compressed_pair<unsigned long, std::__unordered_map_hasher<std::string, std::__hash_value_type<std::string, LazyLoadableModuleRef>, std::hash<std::string>, std::equal_to<std::string>>> { unsigned long long __value_; } __p2_; struct __compressed_pair<float, std::__unordered_map_equal<std::string, std::__hash_value_type<std::string, LazyLoadableModuleRef>, std::equal_to<std::string>, std::hash<std::string>>> { float __value_; } __p3_; } __table_; } _optimizedNoDeviceModuleCache;
    struct recursive_mutex { struct _opaque_pthread_mutex_t { long long __sig; char __opaque[56]; } __m_; } _executableMutex;
    struct recursive_mutex { struct _opaque_pthread_mutex_t { long long __sig; char __opaque[56]; } __m_; } _originalModuleMutex;
    NSObject<OS_dispatch_queue> *_specializationDispatchQueue;
    struct mutex { struct _opaque_pthread_mutex_t { long long __sig; char __opaque[56]; } __m_; } _specializationsPendingMutex;
    struct condition_variable { struct _opaque_pthread_cond_t { long long __sig; char __opaque[40]; } __cv_; } _specializationsPendingCV;
    struct atomic<int> { struct __cxx_atomic_impl<int, std::__cxx_atomic_base_impl<int>> { _Atomic int __a_value; } __a_; } _specializationsPending;
    struct atomic<bool> { struct __cxx_atomic_impl<bool, std::__cxx_atomic_base_impl<bool>> { _Atomic BOOL __a_value; } __a_; } _originalModuleIsOptimized;
    NSArray *_targetOperations;
    NSDictionary *_feeds;
    unsigned long long _modelUID;
    NSString *_modelTime;
    unsigned long long _compilationID;
    unsigned long long _evDumpModuleFlag;
    unsigned long long _sharedEventSignalValue;
    NSString *_evDumpModulePath;
    NSString *_modelFileArchivePath;
    NSString *_dumpCompiledProductsPath;
    NSFileManager *_fileManager;
    struct os_unfair_lock_s { unsigned int _os_unfair_lock_opaque; } _encodeCountLock;
    unsigned long long _encodeCount;
    BOOL _enableCommitAndContinue;
    BOOL _enableProfilingOpNames;
    BOOL _briefProfilingOpNames;
    BOOL _simulateANECompileFailure;
    BOOL _simulateANELoadModelFailure;
    BOOL _runPlacementPass;
    BOOL _useCostModel;
    BOOL _oldCostModelPass;
    BOOL _printCostModel;
    BOOL _generateRuntimeExecutionReport;
    BOOL _legacyANEQuantization;
    BOOL _keepANECUnitNameAttrs;
    BOOL _disablePreEncodeTI;
    BOOL _enablePreEncodeTIReadInputs;
    BOOL _enableRuntimeTIVerifiers;
    BOOL _disableANECaching;
    BOOL _disableANEFallback;
    BOOL _enableANECModuleValidation;
    long long _forcePlacementOnDevice;
    unsigned long long _specializationCountMax;
    unsigned long long _specializationCount;
}

@property unsigned long long options;
@property (readonly) NSArray *feedTensors;
@property (readonly) NSArray *targetTensors;

+ (unsigned long long)getValidateNetworkSupportedVersion;
+ (struct __CFDictionary { } *)validateNetworkWithParams:(struct __CFDictionary { } *)a0 apiVersion:(unsigned long long)a1;
+ (id)executableWithMPSGraphPackageAtURL:(id)a0 compilationDescriptor:(id)a1 error:(id *)a2;
+ (id)executableWithMLIRSourceFromURL:(id)a0 executableDescriptor:(id)a1 error:(id *)a2;
+ (id)executablesWithMLIRSourceForMultipleModules:(id)a0 executableDescriptor:(id)a1 regionNames:(id)a2;

- (void)dealloc;
- (id)debugDescription;
- (void).cxx_destruct;
- (id).cxx_construct;
- (void)dump;
- (id)getOutputShapes;
- (id)encodeToCommandBuffer:(id)a0 inputsArray:(id)a1 resultsArray:(id)a2 executionDescriptor:(id)a3;
- (id)getInputShapes;
- (id)getOutputTypesWithDevice:(id)a0 inputTypes:(id)a1 compilationDescriptor:(id)a2;
- (id)initWithMILProgram:(void *)a0 executableDescriptor:(id)a1;
- (id)initWithMPSGraphPackageAtURL:(id)a0 compilationDescriptor:(id)a1;
- (id)runAsyncWithMTLCommandQueue:(id)a0 inputsArray:(id)a1 resultsArray:(id)a2 executionDescriptor:(id)a3;
- (id)runWithMTLCommandQueue:(id)a0 inputsArray:(id)a1 resultsArray:(id)a2;
- (void)serializeToMPSGraphPackageAtURL:(id)a0 descriptor:(id)a1;
- (void)commonPostInit:(void *)a0;
- (id)initWithMPSGraphPackageAtURLCommon:(id)a0 compilationDescriptor:(id)a1 error:(id *)a2;
- (id)runInternalWithDevice:(id)a0 commandBuffer:(id)a1 feedsDictionary:(id)a2 resultsDictionary:(id)a3 executableExecutionDescriptor:(id)a4 mpsGraphOwnedCommandBuffer:(BOOL)a5;
- (id)allocateTensorDataTargetsForDevice:(id)a0 inputsArray:(id)a1;
- (void)aneRegionOpsHashSet:(void *)a0;
- (void)checkCallablesForModule:(void *)a0;
- (struct OwningOpRef<mlir::ModuleOp> { struct ModuleOp { struct Operation *x0; } x0; })cloneForFeeds:(id)a0 targetTensors:(id)a1 targetOperations:(id)a2;
- (void)commonPreInitWithDescriptor:(id)a0;
- (struct vector<mlir::Type, std::allocator<mlir::Type>> { struct Type *x0; struct Type *x1; struct __compressed_pair<mlir::Type *, std::allocator<mlir::Type>> { struct Type *x0; } x2; })convertMPSGraphShapesToMLIRTypes:(id)a0;
- (struct vector<mlir::Type, std::allocator<mlir::Type>> { struct Type *x0; struct Type *x1; struct __compressed_pair<mlir::Type *, std::allocator<mlir::Type>> { struct Type *x0; } x2; })convertMPSGraphShapesToMLIRTypes:(id)a0 funcOp:(struct FuncOp { struct Operation *x0; })a1 compilationDescriptor:(id)a2;
- (id)createMLIRLibraryWithMPSGraphPackage:(id)a0 packageKey:(id)a1 appendOptimizedModules:(BOOL)a2;
- (void)dumpCompiledProducts;
- (id)emitObjCToURL:(id)a0 test:(BOOL)a1;
- (void)emitObjUnitTestToUrl:(id)a0;
- (id)emitViewerSPI;
- (void)emitViewerSPIToURL:(id)a0;
- (id)emitViewerSPIWithDevice:(id)a0 inputShapes:(id)a1 compilationDescriptor:(id)a2;
- (id)encodeWithMPSCommandBuffer:(id)a0 inputsArray:(id)a1 resultsArray:(id)a2 executionDescriptor:(id)a3;
- (struct vector<mlir::NamedAttribute, std::allocator<mlir::NamedAttribute>> { struct NamedAttribute *x0; struct NamedAttribute *x1; struct __compressed_pair<mlir::NamedAttribute *, std::allocator<mlir::NamedAttribute>> { struct NamedAttribute *x0; } x2; })getAttributesFromDescriptors:(id)a0 context:(void *)a1 device:(id)a2;
- (struct FuncOp { struct Operation *x0; })getEntryFuncOp;
- (struct FuncOp { struct Operation *x0; })getEntryFuncOpForModule:(struct ModuleOp { struct Operation *x0; })a0;
- (id)getIR;
- (void *)getNewRuntimeForDevice:(id)a0 module:(struct ModuleOp { struct Operation *x0; })a1 inputShapes:(id)a2 compilationDescriptor:(id)a3 fallingBack:(BOOL)a4 fallbackRuntimeKey:(const void *)a5;
- (void *)getNewRuntimeForDevice:(id)a0 module:(struct ModuleOp { struct Operation *x0; })a1 inputsArray:(id)a2 compilationDescriptor:(id)a3;
- (id)getOperationsToVisitForOperation:(id)a0 visitedOperations:(id)a1;
- (unsigned long long)getOptimizedModuleCacheSize;
- (unsigned long long)getOptimizedNoDeviceModuleCacheSize;
- (unsigned long long)getResourcesTotalSize;
- (id)getTargetShapesForDevice:(id)a0 inputsArray:(id)a1;
- (id)getTensorDataArraysWithDevice:(id)a0 feedsDictionary:(id)a1 resultsDictionary:(id)a2 inputsArray:(id)a3 resultsArray:(id)a4;
- (id)initWithCoreMLPackage:(id)a0 executableDescriptor:(id)a1;
- (id)initWithCoreMLPackageAtURL:(id)a0 compilationDescriptor:(id)a1;
- (id)initWithGraph:(id)a0 device:(id)a1 feeds:(id)a2 targetTensors:(id)a3 targetOperations:(id)a4 executableDescriptor:(id)a5;
- (id)initWithMILProgramWithURL:(id)a0 executableDescriptor:(id)a1;
- (id)initWithMLIRBytecode:(id)a0 executableDescriptor:(id)a1;
- (id)initWithMLIRCommon:(struct unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>> { struct __compressed_pair<llvm::MemoryBuffer *, std::default_delete<llvm::MemoryBuffer>> { struct MemoryBuffer *x0; } x0; })a0 executableDescriptor:(id)a1 error:(id *)a2;
- (id)initWithMLIRModule:(struct ModuleOp { struct Operation *x0; })a0 executableDescriptor:(id)a1;
- (id)initWithMLIRSource:(id)a0 executableDescriptor:(id)a1;
- (id)initWithMLIRSourceFromURL:(id)a0 executableDescriptor:(id)a1;
- (void)initializeMLIR;
- (id)initializeWithMLIRModule:(struct ModuleOp { struct Operation *x0; })a0 executableDescriptor:(id)a1;
- (BOOL)isExecutableForFeeds:(id)a0 targetTensors:(id)a1 targetOperations:(id)a2 compilationDescriptor:(id)a3;
- (id)lazyInitWithModuleURL:(id)a0 executableDescriptor:(id)a1 callablesDescription:(id)a2 moduleResourcesLoader:(struct shared_ptr<ModuleResourcesLoader> { struct ModuleResourcesLoader *x0; struct __shared_weak_count *x1; })a3;
- (struct OwningOpRef<mlir::ModuleOp> { struct ModuleOp { struct Operation *x0; } x0; })optimizationPassesWithDevice:(id)a0 sourceModule:(void *)a1 compilationID:(unsigned long long)a2 compilationDescriptor:(id)a3;
- (void)optimizeOriginalModule;
- (struct ReturnOp { struct Operation *x0; })returnOpForFunctionInModule:(struct ModuleOp { struct Operation *x0; })a0;
- (id)runAsyncWithCommandQueue:(id)a0 inputsArray:(id)a1 resultsArray:(id)a2 executionDescriptor:(id)a3;
- (id)runAsyncWithDevice:(id)a0 inputsArray:(id)a1 resultsArray:(id)a2 executionDescriptor:(id)a3;
- (id)runInternalWithDevice:(id)a0 commandBuffer:(id)a1 feeds:(id)a2 results:(id)a3 executableExecutionDescriptor:(id)a4 mpsGraphOwnedCommandBuffer:(BOOL)a5;
- (id)runWithDevice:(id)a0 inputsArray:(id)a1 resultsArray:(id)a2 executionDescriptor:(id)a3;
- (id)runWithMTLCommandQueue:(id)a0 inputsArray:(id)a1 resultsArray:(id)a2 executionDescriptor:(id)a3;
- (void)setSpecializationCountMax:(unsigned long long)a0;
- (void)specializeForMultipleInputTypesWithDevice:(id)a0 multipleInputTypes:(id)a1 compilationDescriptor:(id)a2;
- (void)specializeWithDevice:(id)a0 inputShapes:(id)a1 compilationDescriptor:(id)a2;
- (void)specializeWithDevice:(id)a0 inputTypes:(id)a1 compilationDescriptor:(id)a2;
- (struct ModuleOp { struct Operation *x0; })specializeWithDevice:(id)a0 inputsArray:(id)a1 compilationDescriptor:(id)a2;
- (struct ModuleOp { struct Operation *x0; })specializedModuleWithDevice:(id)a0 inputShapes:(id)a1 compilationDescriptor:(id)a2 fallingBack:(BOOL)a3 fallbackRuntimeKey:(const void *)a4;

@end
